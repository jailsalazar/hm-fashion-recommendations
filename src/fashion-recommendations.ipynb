{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H&M Personalized Fashion Recommendations\n",
    "\n",
    "This notebook contains the approach taken for the 2022 H&M Personalized Fashion Recommendations Kaggle competition. \n",
    "\n",
    "*Visit repo README.md for instructions on how to execute notebook locally.*\n",
    "\n",
    "Developed By **Jaileen Salazar**\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# RNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, SpatialDropout1D, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import Recall, Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE PATHS\n",
    "TRAIN_PATH = '../data/transactions_train.csv'\n",
    "CUSTOMER_PATH = '../data/customers.csv'\n",
    "ARTICLES_PATH = '../data/articles.csv'\n",
    "\n",
    "# FILE FORMATS\n",
    "#t_dat,customer_id,article_id,price,sales_channel_id\n",
    "TRAIN_FORMAT = {'t_dat':str, 'customer_id':str, 'article_id':str, 'price':float, 'sales_channel_id':int}\n",
    "CUSTOMER_META_FORMAT = {'customer_id':str, 'FN':str, 'Active':str, 'club_member_status':str, 'fashion_news_frequency':str, 'age':int, 'postal_code':str}\n",
    "ARTICLE_META_FORMAT = {'article_id':str, 'product_code':str, 'prod_name':str, 'product_type_no':int, 'product_type_name':str, 'product_group_name':str, 'graphical_appearance_no':int, 'graphical_appearance_name':str, 'colour_group_code':str, 'colour_group_name':str, 'perceived_colour_value_id':str, 'perceived_colour_value_name':str, 'perceived_colour_master_id':str, 'perceived_colour_master_name':str, 'department_no':int, 'department_name':str, 'index_code':str, 'index_name':str, 'index_group_no':int, 'index_group_name':str, 'section_no':int, 'section_name':str, 'garment_group_no':int, 'garment_group_name':str, 'detail_desc':str} \n",
    "SUBMISSION_HEADERS = ['customer_id','prediction']\n",
    "\n",
    "# Regular expressions used for preprocessing\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "HTML_TAGS_RE = re.compile('<.*?>')\n",
    "TOKEN_FILTERS = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion Recommendations Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionRecommendations():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _preprocess_text(this, text):\n",
    "        \"\"\"\"\"\n",
    "            Text preprocessing to polish data.\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        text = HTML_TAGS_RE.sub('', text)\n",
    "        text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "        text = BAD_SYMBOLS_RE.sub('', text)\n",
    "        return text\n",
    "\n",
    "    def parse_data(this, filepath, datatypes):\n",
    "        \"\"\"\n",
    "            Open file, apply preprocessing and return formatted dataframe\n",
    "        \"\"\"\n",
    "        df_data = pd.read_csv(filepath, dtype=datatypes)\n",
    "        return df_data\n",
    "\n",
    "    def save_results(this, ids, predictions, filename, headers):\n",
    "        data = zip(ids, predictions)\n",
    "        with open(filename, 'w', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(headers)\n",
    "            writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
